{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import gym\n",
    "from gym import spaces\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "MAX_ACCOUNT_BALANCE = 2147483647\n",
    "MAX_NUM_UNITS = 100000\n",
    "MAX_UNIT_PRICE = 200000\n",
    "INITIAL_ACCOUNT_BALANCE = 10000\n",
    "WINDOW_SIZE = 5\n",
    "DATA_SIZE = 1\n",
    "MDD_REWARD = 0.5\n",
    "\n",
    "mode = 'ppo' # 'ppo', 'a2c'\n",
    "\n",
    "if mode in ['a2c']:\n",
    "    INTERVAL = 1000\n",
    "    EPISODES = 150\n",
    "else:\n",
    "    INTERVAL = 1\n",
    "    EPISODES = 200\n",
    "\n",
    "dsource = 'trunc_data.pkl'\n",
    "model_name = 'universal_model'\n",
    "\n",
    "df = pd.read_pickle(dsource).reset_index(level=0)\n",
    "MAX_STEPS = len(df) - WINDOW_SIZE - 1\n",
    "TIME_STEPS_TRAIN = MAX_STEPS * EPISODES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from stable_baselines3.common.callbacks import BaseCallback\n",
    "from stable_baselines3.common.logger import TensorBoardOutputFormat\n",
    "from stable_baselines3.common.vec_env import SubprocVecEnv\n",
    "\n",
    "#100-period sortino ratio\n",
    "def roll_sortino(df): #t: last time ratio\n",
    "  risk_free = 0 #0 percent\n",
    "  returns = (df - df.shift(-1)).to_numpy()[:-1]\n",
    "  return_negative_normal = returns[returns < 0]\n",
    "  return_negative_std = return_negative_normal.std() if len(return_negative_normal) > 0 else 0\n",
    "  sortino_roll = (returns.mean() - risk_free) / return_negative_std * np.sqrt(100) if return_negative_std > 0 else 0\n",
    "  # print(\"srtdf\", return_negative_normal, 'SSSTD', return_negative_std, 'SRLLL', sortino_roll)\n",
    "  # print(\"SRRL\", sortino_roll)\n",
    "  return sortino_roll\n",
    "\n",
    "def sortino(df, t, algorithm): #time period: m for minute, h for hour, t: truncated\n",
    "  df_truncated = df.head(t)\n",
    "  df_sortino = roll_sortino(df_truncated['{}_return'.format(algorithm)].tail(100))\n",
    "  # print(\"srt\", df_truncated['sortino'], df_truncated['dqn_return'])\n",
    "  sortino_ = 0 if t == 0 else df_sortino\n",
    "  # print(float(sortino_))\n",
    "  return float(sortino_)\n",
    "\n",
    "def sigmoid(x):\n",
    "\treturn 1 / (1 + np.exp(-x))\n",
    "\n",
    "class SummaryWriterCallback(BaseCallback):\n",
    "    def _on_training_start(self):\n",
    "        self._log_freq = 1  # log every INTERVAL calls\n",
    "\n",
    "        output_formats = self.logger.output_formats\n",
    "        # Save reference to tensorboard formatter object\n",
    "        # note: the failure case (not formatter found) is not handled here, should be done with try/except.\n",
    "        self.tb_formatter = next(formatter for formatter in output_formats if isinstance(formatter, TensorBoardOutputFormat))\n",
    "\n",
    "    def _on_step(self) -> bool:\n",
    "        # Log my_custom_reward every _log_freq(th) to tensorboard for each environment\n",
    "        if self.n_calls % self._log_freq == 0:\n",
    "            # if vars(vars(self.locals['env'])['envs'][0])['current_step'] == MAX_STEPS - 1:\n",
    "              total_reward = vars(vars(self.locals['env'])['envs'][0])['total_reward']\n",
    "              mdd = vars(vars(self.locals['env'])['envs'][0])['mdd']\n",
    "              sortino = vars(vars(self.locals['env'])['envs'][0])['sortino']\n",
    "              return_ = vars(vars(self.locals['env'])['envs'][0])['net_worth'] / INITIAL_ACCOUNT_BALANCE\n",
    "              # print(total_reward)\n",
    "            # rewards = self.locals['my_custom_info_dict']['my_custom_reward']\n",
    "            # for i in range(self.locals['env'].num_envs):\n",
    "              self.tb_formatter.writer.add_scalar(\"rewards\", total_reward, self.n_calls)\n",
    "              self.tb_formatter.writer.add_scalar(\"mdd\", mdd, self.n_calls)\n",
    "              self.tb_formatter.writer.add_scalar(\"sortino\", sortino, self.n_calls)\n",
    "              self.tb_formatter.writer.add_scalar(\"return_\", return_, self.n_calls)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BTCTradingEnvCont(gym.Env):\n",
    "    metadata = {'render.modes': ['human']}\n",
    "\n",
    "    def __init__(self, df, algorithm):\n",
    "        super(BTCTradingEnvCont, self).__init__()\n",
    "\n",
    "        self.df = df\n",
    "        self.df['{}_return'.format(algorithm)] = 0.\n",
    "        self.df['mdd'] = 0.\n",
    "        self.df['sortino'] = 0.\n",
    "\n",
    "        self.algorithm = algorithm\n",
    "\n",
    "        # Actions of the format [0]=0 Buy x%, [0]=1 Sell x%, [0]=2 Hold, etc., amount: [1] from 0 to 1\n",
    "        self.action_space = spaces.Box(low=np.array([0, 0]), high=np.array([3, 1]), dtype=np.float16)\n",
    "\n",
    "        # Prices contains the values for the last [WINDOW_SIZE] prices\n",
    "        self.observation_space = spaces.Box(low=0, high=1, shape=(DATA_SIZE + 1, WINDOW_SIZE + 1), dtype=np.float16) # 1 each dimension\n",
    "\n",
    "        self.mdd = 0\n",
    "        self.mdd_last_sell = 0\n",
    "        self.sortino = 0\n",
    "        self.current_reward = 0\n",
    "        self.total_reward = 0\n",
    "\n",
    "    def _next_observation(self):\n",
    "        # Get the BTC data points for the last WINDOW_SIZE days and scale to between 0-16\n",
    "        len_frame = len(self.df.loc[self.current_step: self.current_step + WINDOW_SIZE, 'close'].values)\n",
    "        if DATA_SIZE == 3:\n",
    "          frame = np.array([\n",
    "              np.pad(self.df.loc[self.current_step: self.current_step + WINDOW_SIZE, 'close'].to_numpy(), (0, WINDOW_SIZE + 1 - len_frame), 'edge') / MAX_UNIT_PRICE,\n",
    "              np.pad(self.df.loc[self.current_step: self.current_step + WINDOW_SIZE, 'ewm'].to_numpy(), (0, WINDOW_SIZE + 1 - len_frame), 'edge') / MAX_UNIT_PRICE,\n",
    "              np.pad(self.df.loc[self.current_step: self.current_step + WINDOW_SIZE, 'macd_histo'].to_numpy(), (0, WINDOW_SIZE + 1 - len_frame), 'edge') / MAX_UNIT_PRICE,\n",
    "          ])\n",
    "        elif DATA_SIZE == 1:\n",
    "            self.df.loc[0, 'return'] = 0\n",
    "            frame = np.array([\n",
    "              np.pad(self.df.loc[self.current_step: self.current_step + WINDOW_SIZE, 'return'].to_numpy(), (0, WINDOW_SIZE + 1 - len_frame), 'edge'),\n",
    "          ])\n",
    "        elif DATA_SIZE == 4:\n",
    "            frame = np.array([\n",
    "              np.pad(self.df.loc[self.current_step: self.current_step + WINDOW_SIZE, 'close'].to_numpy(), (0, WINDOW_SIZE + 1 - len_frame), 'edge') / MAX_UNIT_PRICE,\n",
    "              np.pad(self.df.loc[self.current_step: self.current_step + WINDOW_SIZE, 'open'].to_numpy(), (0, WINDOW_SIZE + 1 - len_frame), 'edge') / MAX_UNIT_PRICE,\n",
    "              np.pad(self.df.loc[self.current_step: self.current_step + WINDOW_SIZE, 'high'].to_numpy(), (0, WINDOW_SIZE + 1 - len_frame), 'edge') / MAX_UNIT_PRICE,\n",
    "              np.pad(self.df.loc[self.current_step: self.current_step + WINDOW_SIZE, 'low'].to_numpy(), (0, WINDOW_SIZE + 1 - len_frame), 'edge') / MAX_UNIT_PRICE,\n",
    "          ])\n",
    "\n",
    "        elif DATA_SIZE == 6:\n",
    "            frame = np.array([\n",
    "              np.pad(self.df.loc[self.current_step: self.current_step + WINDOW_SIZE, 'close'].to_numpy(), (0, WINDOW_SIZE + 1 - len_frame), 'edge') / MAX_UNIT_PRICE,\n",
    "              np.pad(self.df.loc[self.current_step: self.current_step + WINDOW_SIZE, 'open'].to_numpy(), (0, WINDOW_SIZE + 1 - len_frame), 'edge') / MAX_UNIT_PRICE,\n",
    "              np.pad(self.df.loc[self.current_step: self.current_step + WINDOW_SIZE, 'high'].to_numpy(), (0, WINDOW_SIZE + 1 - len_frame), 'edge') / MAX_UNIT_PRICE,\n",
    "              np.pad(self.df.loc[self.current_step: self.current_step + WINDOW_SIZE, 'low'].to_numpy(), (0, WINDOW_SIZE + 1 - len_frame), 'edge') / MAX_UNIT_PRICE,\n",
    "              np.pad(self.df.loc[self.current_step: self.current_step + WINDOW_SIZE, 'ewm'].to_numpy(), (0, WINDOW_SIZE + 1 - len_frame), 'edge') / MAX_UNIT_PRICE,\n",
    "              np.pad(self.df.loc[self.current_step: self.current_step + WINDOW_SIZE, 'macd_histo'].to_numpy(), (0, WINDOW_SIZE + 1 - len_frame), 'edge') / MAX_UNIT_PRICE,\n",
    "          ])\n",
    "        \n",
    "        # Append additional data and scale each value to between 0-1\n",
    "        obs = np.append(frame, [[\n",
    "            self.balance / MAX_ACCOUNT_BALANCE,\n",
    "            self.max_net_worth / MAX_ACCOUNT_BALANCE,\n",
    "            self.units_held / MAX_NUM_UNITS,\n",
    "            self.cost_basis / MAX_UNIT_PRICE,\n",
    "            self.total_units_sold / MAX_NUM_UNITS,\n",
    "            self.total_sales_value / (MAX_NUM_UNITS * MAX_UNIT_PRICE),\n",
    "        ]], axis=0)\n",
    "\n",
    "        return obs\n",
    "\n",
    "    def _take_action(self, action):\n",
    "        # Set the current price to a random price within the time step\n",
    "        current_price = self.df.loc[self.current_step, \"close\"]\n",
    "\n",
    "        action_type = action[0]\n",
    "        amount = action[1] # 0 to 1\n",
    "        \n",
    "        if action_type < 1 and amount > 0.001 and self.balance > 100:\n",
    "            # Buy amount % of balance in units\n",
    "            total_possible = self.balance / current_price\n",
    "            units_bought = total_possible * amount\n",
    "            prev_cost = self.cost_basis * self.units_held\n",
    "            additional_cost = units_bought * current_price\n",
    "\n",
    "            self.balance -= additional_cost\n",
    "            self.cost_basis = (prev_cost + additional_cost) / (self.units_held + units_bought)\n",
    "            self.units_held += units_bought\n",
    "            self.df.loc[self.current_step, 'action'] = f'buy {units_bought:5f} @ {current_price}'\n",
    "\n",
    "            # Update new portfolio values\n",
    "            self.net_worth = self.balance + self.units_held * current_price\n",
    "\n",
    "            if self.net_worth > self.max_net_worth:\n",
    "                self.max_net_worth = self.net_worth\n",
    "                self.mdd_base = self.max_net_worth # reset mdd base at ath\n",
    "\n",
    "            if self.net_worth < self.min_net_worth:\n",
    "                self.min_net_worth = self.net_worth\n",
    "\n",
    "            if self.net_worth < self.mdd_base:\n",
    "                self.mdd_base = self.net_worth # mdd calculation here\n",
    "\n",
    "            if self.units_held == 0:\n",
    "                self.cost_basis = 0\n",
    "\n",
    "            # MDD and Sortino after buying\n",
    "            # when max worth goes up, then  min_aft_max resets to the ATH\n",
    "            self.mdd = max(1 - self.mdd_base/self.max_net_worth, self.mdd)\n",
    "\n",
    "            self.df.loc[self.current_step, 'mdd'] = self.mdd\n",
    "            self.sortino = sortino(self.df, self.current_step, self.algorithm) if self.current_step > 100 else 0\n",
    "            self.df.loc[self.current_step, 'sortino'] = self.sortino\n",
    "\n",
    "            # Return tracking\n",
    "            self.df.loc[self.current_step, '{}_return'.format(self.algorithm)] = (self.net_worth - INITIAL_ACCOUNT_BALANCE) / INITIAL_ACCOUNT_BALANCE\n",
    "            self.df.loc[self.current_step, 'holding'] = self.units_held\n",
    "            \n",
    "            # 0 reward for buying\n",
    "            self.current_reward = 0#.0005\n",
    "            self.df.loc[self.current_step, 'reward'] = 0#.0005\n",
    "\n",
    "        elif action_type < 2 and amount > 0.001 and self.units_held > 0.0001:\n",
    "            # Sell amount % of units held\n",
    "            units_sold = self.units_held * amount\n",
    "            self.balance += units_sold * current_price\n",
    "            self.units_held -= units_sold\n",
    "            self.total_units_sold += units_sold\n",
    "            self.total_sales_value += units_sold * current_price\n",
    "            \n",
    "            # Update new portfolio values\n",
    "            self.net_worth = self.balance + self.units_held * current_price\n",
    "\n",
    "            if self.net_worth > self.max_net_worth:\n",
    "                self.max_net_worth = self.net_worth\n",
    "                self.mdd_base = self.max_net_worth # reset mdd base at ath\n",
    "\n",
    "            if self.net_worth < self.min_net_worth:\n",
    "                self.min_net_worth = self.net_worth\n",
    "            \n",
    "            if self.net_worth < self.mdd_base:\n",
    "                self.mdd_base = self.net_worth # mdd calculation here\n",
    "\n",
    "            if self.units_held == 0:\n",
    "                self.cost_basis = 0\n",
    "            \n",
    "            # MDD and Sortino after buying\n",
    "            self.mdd = max(1 - self.mdd_base/self.max_net_worth, self.mdd)\n",
    "            self.df.loc[self.current_step, 'mdd'] = self.mdd\n",
    "            self.sortino = sortino(self.df, self.current_step, self.algorithm) if self.current_step > 100 else 0\n",
    "            self.df.loc[self.current_step, 'sortino'] = self.sortino\n",
    "\n",
    "            # Get current return (correct)\n",
    "            self.df.loc[self.current_step, '{}_return'.format(self.algorithm)] = (self.net_worth - INITIAL_ACCOUNT_BALANCE) / INITIAL_ACCOUNT_BALANCE\n",
    "            self.df.loc[self.current_step, 'holding'] = self.units_held\n",
    "\n",
    "            # Reward calculation\n",
    "            delay_modifier = (self.current_step / len(self.df))\n",
    "\n",
    "            reward_1 = units_sold * (self.df.loc[self.current_step, 'close'] - self.cost_basis) / self.cost_basis if self.cost_basis > 1 else 0\n",
    "            reward_2 = MDD_REWARD * (self.mdd_last_sell - self.df.loc[self.current_step, 'mdd'])\n",
    "            reward_3 = 0#self.sortino / 10\n",
    "            self.current_reward = reward_1 + reward_2 + reward_3\n",
    "\n",
    "            self.mdd_last_sell = self.df.loc[self.current_step, 'mdd']\n",
    "\n",
    "            self.df.loc[self.current_step, 'reward'] = f'{self.current_reward:2f} || {reward_1:3f} {reward_2:3f}'\n",
    "\n",
    "            self.df.loc[self.current_step, 'action'] = f'sell {units_sold:5f} @ {current_price}'\n",
    "        \n",
    "        else: # HODL\n",
    "            # Update new portfolio values\n",
    "            self.net_worth = self.balance + self.units_held * current_price\n",
    "\n",
    "            if self.net_worth > self.max_net_worth:\n",
    "                self.max_net_worth = self.net_worth\n",
    "                self.mdd_base = self.max_net_worth # reset mdd base at ath\n",
    "\n",
    "            if self.net_worth < self.min_net_worth:\n",
    "                self.min_net_worth = self.net_worth\n",
    "\n",
    "            if self.net_worth < self.mdd_base:\n",
    "                self.mdd_base = self.net_worth # mdd calculation here\n",
    "\n",
    "            if self.units_held == 0:\n",
    "                self.cost_basis = 0\n",
    "\n",
    "            # MDD and Sortino after buying\n",
    "            self.mdd = max(1 - self.mdd_base/self.max_net_worth, self.mdd)\n",
    "            self.df.loc[self.current_step, 'mdd'] = self.mdd\n",
    "            self.sortino = sortino(self.df, self.current_step, self.algorithm) if self.current_step > 100 else 0\n",
    "            self.df.loc[self.current_step, 'sortino'] = self.sortino\n",
    "\n",
    "            # Get current return (correct)\n",
    "            self.df.loc[self.current_step, '{}_return'.format(self.algorithm)] = (self.net_worth - INITIAL_ACCOUNT_BALANCE) / INITIAL_ACCOUNT_BALANCE\n",
    "            self.df.loc[self.current_step, 'holding'] = self.units_held\n",
    "\n",
    "            self.df.loc[self.current_step, 'action'] = f'hold {self.units_held:5f} @ {self.cost_basis}'\n",
    "\n",
    "            # Reward # HODL \n",
    "            self.current_reward = self.units_held * (-0.0005 + min(0, 0.0001 * (self.net_worth - INITIAL_ACCOUNT_BALANCE) / INITIAL_ACCOUNT_BALANCE))\n",
    "            self.df.loc[self.current_step, 'reward'] = self.current_reward\n",
    "        self.total_reward += self.current_reward\n",
    "\n",
    "    def step(self, action):\n",
    "        # Execute one time step within the environment\n",
    "        end_ = len(self.df) - WINDOW_SIZE - 1\n",
    "        if self.current_step == end_ - 1:\n",
    "          self._take_action([1,1]) #sell all\n",
    "        else:\n",
    "          self._take_action(action)\n",
    "\n",
    "        self.current_step += 1\n",
    "        # print(self.current_step)\n",
    "        # if self.current_step > len(self.df.loc[:, 'close'].values) - WINDOW_SIZE - 1 and mode != 'td3':\n",
    "        #     self.current_step = self.current_step - WINDOW_SIZE - 1\n",
    "        obs = self._next_observation()\n",
    "        done = self.current_step == end_\n",
    "        if done:\n",
    "          print('RW', self.total_reward, \"MD\", self.mdd, 'RET', (self.net_worth - INITIAL_ACCOUNT_BALANCE) / INITIAL_ACCOUNT_BALANCE)\n",
    "        return obs, self.current_reward, done, {}\n",
    "\n",
    "    def reset(self):\n",
    "        # Reset the state of the environment to an initial state\n",
    "        self.balance = INITIAL_ACCOUNT_BALANCE\n",
    "        self.net_worth = INITIAL_ACCOUNT_BALANCE\n",
    "        self.max_net_worth = INITIAL_ACCOUNT_BALANCE\n",
    "        self.mdd_base = INITIAL_ACCOUNT_BALANCE\n",
    "        self.mdd = 0\n",
    "        self.mdd_last_sell = 0\n",
    "        self.min_net_worth = INITIAL_ACCOUNT_BALANCE\n",
    "        self.units_held = 0\n",
    "        self.cost_basis = 0\n",
    "        self.total_units_sold = 0\n",
    "        self.total_sales_value = 0\n",
    "        self.total_reward = 0\n",
    "\n",
    "        # Set the current step to a random point within the data frame\n",
    "        # self.current_step = random.randint(0, len(self.df.loc[:, 'open'].values) - WINDOW_SIZE - 1)\n",
    "        self.current_step = 0\n",
    "\n",
    "        return self._next_observation()\n",
    "\n",
    "    def render(self, mode='human', close=False):\n",
    "        # Render the environment to the screen\n",
    "        profit = self.net_worth - INITIAL_ACCOUNT_BALANCE\n",
    "\n",
    "        print(f'Step: {self.current_step}')\n",
    "        print(f'Balance: {self.balance}')\n",
    "        print(f'Units held: {self.units_held} (Total sold: {self.total_units_sold})')\n",
    "        print(f'Avg cost for held units: {self.cost_basis} (Total sales value: {self.total_sales_value})')\n",
    "        print(f'Net worth: {self.net_worth} (Max net worth: {self.max_net_worth}, min: {self.min_net_worth})')\n",
    "        print(f'MDD: {self.mdd} Sortino: {self.sortino})')\n",
    "        print(f'Profit: {profit}')\n",
    "        print()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime as dt\n",
    "\n",
    "from stable_baselines3.common.vec_env import DummyVecEnv\n",
    "from stable_baselines3 import PPO, A2C\n",
    "import pandas as pd\n",
    "from stable_baselines3.common.noise import NormalActionNoise\n",
    "from stable_baselines3.common.callbacks import CallbackList, CheckpointCallback, EvalCallback\n",
    "import pickle, random\n",
    "\n",
    "# The algorithms require a vectorized environment to run\n",
    "env = DummyVecEnv([lambda: BTCTradingEnvCont(df, mode)])\n",
    "\n",
    "# TD3 actions\n",
    "n_actions = env.action_space.shape[-1]\n",
    "action_noise = NormalActionNoise(mean=np.zeros(n_actions), sigma=0.1 * np.ones(n_actions))\n",
    "\n",
    "eval_callback = EvalCallback(env, best_model_save_path=f\"./models/B3/{mode}_best_model\", log_path=\"./models/B3/{mode}_res\", eval_freq=len(df))\n",
    "checkpoint_callback = CheckpointCallback(save_freq=10 * len(df), save_path=\"./models/B3/{mode}-log\")\n",
    "callback = CallbackList([checkpoint_callback, SummaryWriterCallback()])\n",
    "\n",
    "if mode == 'ppo': \n",
    "  model = PPO(\"MlpPolicy\", env, verbose=1, tensorboard_log=\"./models/B3/xlog\")\n",
    "elif mode == 'a2c':\n",
    "  model = A2C(\"MlpPolicy\", env, verbose=1, tensorboard_log=\"./models/B3/xlog\")\n",
    "\n",
    "# model.learn(total_timesteps=TIME_STEPS_TRAIN, log_interval=INTERVAL, callback=callback)\n",
    "model.learn(total_timesteps=TIME_STEPS_TRAIN, log_interval=INTERVAL)\n",
    "\n",
    "# Save model\n",
    "model.save(f'model-cont-{mode}-{DATA_SIZE}-{WINDOW_SIZE}-{MDD_REWARD}-{random.randint(0,99)}')\n",
    "pickle.dump({'name': f'{mode}', 'data': df}, open(f\"models/B3/data-cont{mode}-{DATA_SIZE}-{WINDOW_SIZE}-{random.randint(0,99)}.pkl\", 'ab'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from plotly.subplots import make_subplots\n",
    "import plotly.graph_objects as go\n",
    "\n",
    "def plot_fig(df_, title, custom_range=[0,1]):\n",
    "  df = df_.head(len(df_) - WINDOW_SIZE - 1)\n",
    "  # Price line\n",
    "  fig = make_subplots(rows=3, cols=1, \n",
    "                      specs = [[{\"secondary_y\": False}], \n",
    "                              [{\"secondary_y\": False}],\n",
    "                              [{\"secondary_y\": False}]])\n",
    "  fig.update_layout(\n",
    "      autosize=False,\n",
    "      width=1300,\n",
    "      height=800,\n",
    "      title_text=title,\n",
    "    )\n",
    "\n",
    "  initial_btc_price = float(df.head(1)['close'])\n",
    "  fig.append_trace(\n",
    "      go.Scatter(\n",
    "          x=df.index,\n",
    "          y=df['close'] / initial_btc_price,\n",
    "          # line=dict(color='#ff9900', width=1),\n",
    "          name='BTC/benchmark',\n",
    "          # showlegend=False,\n",
    "          legendgroup='1',\n",
    "          marker=dict(\n",
    "          size=42,\n",
    "          # I want the color to be green if \n",
    "          # lower_limit ≤ y ≤ upper_limit\n",
    "          # else red\n",
    "          color='black',\n",
    "        )\n",
    "      ), row=1, col=1\n",
    "  )\n",
    "\n",
    "  # Sortino\n",
    "  fig.add_trace(\n",
    "      go.Scatter(\n",
    "          x=df.index,\n",
    "          y=df['sortino'],\n",
    "          name='Sortino',\n",
    "      ), row=2, col=1\n",
    "  )\n",
    "\n",
    "  # Portfolio\n",
    "  fig.append_trace(\n",
    "    go.Scatter(\n",
    "          x=df.index,\n",
    "          y=df[f'{mode}_return'] + 1,\n",
    "          # line=dict(color='#ff9900', width=1),\n",
    "          name='Portfolio',\n",
    "          # showlegend=False,\n",
    "          marker=dict(\n",
    "          size=42,\n",
    "          # I want the color to be green if \n",
    "          # lower_limit ≤ y ≤ upper_limit\n",
    "          # else red\n",
    "          color='red',\n",
    "        )\n",
    "      ), row=1, col=1\n",
    "  )\n",
    "\n",
    "  # MDD\n",
    "  fig.add_trace(\n",
    "    go.Scatter(\n",
    "          x=df.index,\n",
    "          y=-df['mdd'],\n",
    "          # line=dict(color='#ff9900', width=1),\n",
    "          name='MDD',\n",
    "          # showlegend=False,\n",
    "          marker=dict(\n",
    "          size=42,\n",
    "          # I want the color to be green if \n",
    "          # lower_limit ≤ y ≤ upper_limit\n",
    "          # else red\n",
    "          color='blue',\n",
    "        )\n",
    "      ), row=3, col=1\n",
    "  )\n",
    "  return fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt \n",
    "\n",
    "#testing with other data\n",
    "data_addrs = ['hourly_bull.pkl', 'hourly_bear.pkl', 'minutely_crab.pkl', 'minutely_bull.pkl']\n",
    "results_ = []\n",
    "\n",
    "def evaluate_model(addr):   \n",
    "    dat_te = pd.read_pickle(addr)\n",
    "    dat_te = dat_te.reset_index(level=0)\n",
    "\n",
    "    env_te = DummyVecEnv([lambda: BTCTradingEnvCont(dat_te, mode)])\n",
    "\n",
    "    obs_te = env_te.reset()\n",
    "\n",
    "    for i in range(len(dat_te) - WINDOW_SIZE - 1):\n",
    "        action, _states = model.predict(obs_te)\n",
    "        obs_te, rewards, done, info = env_te.step(action)\n",
    "        if (i + 1) % 500 == 0 or i == len(dat_te) - 3 - WINDOW_SIZE:\n",
    "          env_te.render()\n",
    "    \n",
    "    fig = plot_fig(dat_te, f'./models/B3/{mode}-{addr}-test', custom_range=[min(dat_te[f'{mode}_return']), max(dat_te[f'{mode}_return'])])\n",
    "\n",
    "    res_ = {\n",
    "        'name': f'test-{addr}-{mode}-{DATA_SIZE}-{WINDOW_SIZE}',\n",
    "        'data': dat_te,\n",
    "        'figure': fig\n",
    "    }\n",
    "\n",
    "    results_.append(res_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for addr in data_addrs:\n",
    "    evaluate_model(addr)\n",
    "\n",
    "pickle.dump(results_, open(f'./models/B3/{mode}-cont-results.pkl', 'ab'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_[3]['figure']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_delta(dataset, indexe):\n",
    "  benchmark = dataset[indexe]['figure']['data'][0]['y']\n",
    "  portfolio = dataset[indexe]['figure']['data'][2]['y']\n",
    "  delta = portfolio/benchmark\n",
    "  ave_delta = delta.mean()\n",
    "  return ave_delta - 1\n",
    "\n",
    "def get_data_note(dataset, indexe):\n",
    "  portfolio = dataset[indexe]['figure']['data'][2]['y'][-1]\n",
    "  mdd = dataset[indexe]['figure']['data'][3]['y'][-1]\n",
    "  sortino = dataset[indexe]['figure']['data'][1]['y'][-1]\n",
    "  return portfolio - 1, -mdd, sortino\n",
    "\n",
    "for i in range (4):\n",
    "  print(get_delta(results_, i), get_data_note(results_, i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "f3ce3df792d36067c304b10e101c0644826d26e159008826d766ba61b27006a4"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
