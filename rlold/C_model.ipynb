{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from ENV import *\n",
    "import gym\n",
    "import numpy as np\n",
    "import warnings\n",
    "\n",
    "# Suppress FutureWarning and UserWarning\n",
    "warnings.filterwarnings(\"ignore\", category=FutureWarning)\n",
    "warnings.filterwarnings(\"ignore\", category=UserWarning)\n",
    "\n",
    "algorithm_name = 'ppo'\n",
    "space_mode = 'discrete'\n",
    "\n",
    "if algorithm_name in ['a2c']:\n",
    "  INTERVAL = 1000\n",
    "  EPISODES = 2\n",
    "else:\n",
    "  INTERVAL = 1\n",
    "  EPISODES = 200\n",
    "\n",
    "fn = 'btc22clean'\n",
    "data_source = f'../data/{fn}.csv'\n",
    "df = pd.read_pickle(data_source).reset_index(level=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Callback\n",
    "from stable_baselines3.common.callbacks import BaseCallback\n",
    "from stable_baselines3.common.logger import TensorBoardOutputFormat\n",
    "\n",
    "class SummaryWriterCallback(BaseCallback):\n",
    "    def _on_training_start(self):\n",
    "        self._log_freq = 1  # log every INTERVAL calls\n",
    "\n",
    "        output_formats = self.logger.output_formats\n",
    "        # Save reference to tensorboard formatter object\n",
    "        # note: the failure case (not formatter found) is not handled here, should be done with try/except.\n",
    "        self.tb_formatter = next(formatter for formatter in output_formats if isinstance(formatter, TensorBoardOutputFormat))\n",
    "\n",
    "    def _on_step(self) -> bool:\n",
    "        # Log my_custom_reward every _log_freq(th) to tensorboard for each environment\n",
    "        if self.n_calls % self._log_freq == 0:\n",
    "            if vars(vars(vars(self.locals['env'])['envs'][0])['gym_env'])['current_step'] == MAX_STEPS - 1:\n",
    "              total_reward = vars(vars(self.locals['env'])['envs'][0])['total_reward']\n",
    "              mdd = vars(vars(self.locals['env'])['envs'][0])['mdd']\n",
    "              sortino = vars(vars(self.locals['env'])['envs'][0])['sortino']\n",
    "              return_ = vars(vars(self.locals['env'])['envs'][0])['net_worth'] / INITIAL_ACCOUNT_BALANCE\n",
    "              # print(total_reward)\n",
    "            # rewards = self.locals['my_custom_info_dict']['my_custom_reward']\n",
    "            # for i in range(self.locals['env'].num_envs):\n",
    "              self.tb_formatter.writer.add_scalar(\"rewards\", total_reward, self.n_calls)\n",
    "              self.tb_formatter.writer.add_scalar(\"mdd\", mdd, self.n_calls)\n",
    "              self.tb_formatter.writer.add_scalar(\"sortino\", sortino, self.n_calls)\n",
    "              self.tb_formatter.writer.add_scalar(\"return_\", return_, self.n_calls)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class TradingAgent(gym.env):\n",
    "  metadata = {'render.modes': ['human']}\n",
    "\n",
    "  def __init__(self, df, algorithm_name, space_mode):\n",
    "    super().__init__()\n",
    "\n",
    "    self.df = df\n",
    "    self.df['return'] = 0\n",
    "    self.df['mdd'] = 0\n",
    "    \n",
    "    self.algorithm_name = algorithm_name\n",
    "    self.space_mode = space_mode # discrete or continuous\n",
    "\n",
    "    # ACTION space\n",
    "    if self.space_mode == 'discrete':\n",
    "      # long, short, hold, close = 4\n",
    "      self.action_space = gym.Space.Discrete(len(ACTIONS)) \n",
    "    else:\n",
    "      # array[0] ACTIONS\n",
    "      # array[1] AMOUNT - portion of portfolio, max is 1\n",
    "      # array[2] LEVERAGE - later\n",
    "      # array[3] SET_TP - later\n",
    "      # array[4] SET_SL - later\n",
    "      self.action_space = gym.Space.Box(low=np.array([0,0]), high=np.array([len(ACTIONS),1]), dtype=np.float16)\n",
    "\n",
    "    # OBSERVATION space\n",
    "      if self.space_mode == 'discrete':\n",
    "        # arr[0] CLOSE - last close in value in log USDT\n",
    "        # arr[1] VOLUME - in log\n",
    "        # arr[2] DELTA - close / open in portion\n",
    "        # arr[3] AMPLITUDE - high / low in portion\n",
    "        # arr[4] CLOSE_OVER_LOW close / low in portion\n",
    "        self.observation_space = gym.Space.Box(\n",
    "          #       0   1   2   3   4\n",
    "          low= [-30,-30, -1,  0,  0][:FEATURES], \n",
    "          high=[ 30, 30, 99, 99, 99][:FEATURES],\n",
    "          shape=(WINDOW_SIZE,), \n",
    "          dtype=np.float16)\n",
    "\n",
    "    self.mdd = 0\n",
    "    self.mdd_last_sell = 0\n",
    "    self.current_reward = 0\n",
    "    self.total_reward = 0\n",
    "    self.current_step = 0\n",
    "\n",
    "  def _next_observation(self):\n",
    "    # Get data points for the last WINDOW_SIZE \n",
    "\n",
    "    pass\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
