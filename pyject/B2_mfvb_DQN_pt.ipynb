{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "dat = pd.read_pickle('minutely_bull.pkl')\n",
    "model_file_suffix = 'mbu_3'\n",
    "\n",
    "window_size, episode_count = 3, 150\n",
    "data_to_modify = dat.reset_index(level=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "# agent.memory\n",
    "import random\n",
    "from collections import namedtuple\n",
    "\n",
    "Transition = namedtuple('Transition',\n",
    "                        ('state', 'action', 'next_state', 'reward'))\n",
    "\n",
    "\n",
    "class ReplayMemory(object):\n",
    "\n",
    "    def __init__(self, capacity):\n",
    "        self.capacity = capacity\n",
    "        self.memory = []\n",
    "        self.position = 0\n",
    "\n",
    "    def push(self, *args):\n",
    "        \"\"\"Saves a transition.\"\"\"\n",
    "        if len(self.memory) < self.capacity:\n",
    "            self.memory.append(None)\n",
    "        self.memory[self.position] = Transition(*args)\n",
    "        self.position = (self.position + 1) % self.capacity\n",
    "\n",
    "    def sample(self, batch_size):\n",
    "        return random.sample(self.memory, batch_size)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.memory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "# agent.model\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "class DQN(nn.Module):\n",
    "\tdef __init__(self, state_size, action_size):\n",
    "\t\tsuper(DQN, self).__init__()\n",
    "\t\tself.main = nn.Sequential(\n",
    "\t\t\tnn.Linear(state_size, 64),\n",
    "\t\t\tnn.LeakyReLU(0.01, inplace=True),\n",
    "\t\t\tnn.Linear(64, 32),\n",
    "\t\t\tnn.LeakyReLU(0.01, inplace=True),\n",
    "\t\t\tnn.Linear(32, 16),\n",
    "\t\t\tnn.LeakyReLU(0.01, inplace=True),\n",
    "\t\t\tnn.Linear(16, 8),\n",
    "\t\t\tnn.LeakyReLU(0.01, inplace=True),\n",
    "\t\t\tnn.Linear(8, action_size),\n",
    "\t\t)\n",
    "\t\n",
    "\tdef forward(self, input):\n",
    "\t\treturn self.main(input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "# agent.agent\n",
    "import numpy as np\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "import os\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "data_size = 3\n",
    "\n",
    "class Agent:\n",
    "\tdef __init__(self, state_size, is_eval=False):\n",
    "\t\tself.state_size = data_size * state_size # normalized previous days || 3: 3 values\n",
    "\t\tself.action_size = 3 # sit, buy, sell\n",
    "\t\tself.memory = ReplayMemory(10000)\n",
    "\t\tself.inventory = []\n",
    "\t\tself.is_eval = is_eval\n",
    "\n",
    "\t\tself.gamma = 0.9\n",
    "\t\tself.epsilon = 0.9\n",
    "\t\tself.epsilon_min = 0.01\n",
    "\t\tself.epsilon_decay = 0.99\n",
    "\t\tself.batch_size = 16\n",
    "\t\tif os.path.exists('models/B2/target_model_' + model_file_suffix):\n",
    "\t\t\tself.policy_net = torch.load('models/B2/policy_model_' + model_file_suffix, map_location=device)\n",
    "\t\t\tself.target_net = torch.load('models/B2/target_model_' + model_file_suffix, map_location=device)\n",
    "\t\telse:\n",
    "\t\t\tself.policy_net = DQN(data_size * state_size, self.action_size).to(device)\n",
    "\t\t\tself.target_net = DQN(data_size * state_size, self.action_size).to(device)\n",
    "\t\tself.optimizer = optim.RMSprop(self.policy_net.parameters(), lr=0.0005, momentum=0.8)\n",
    "\n",
    "\tdef act(self, state):\n",
    "\t\tif not self.is_eval and np.random.rand() <= self.epsilon:\n",
    "\t\t\treturn random.randrange(self.action_size)\n",
    "\n",
    "\t\ttensor = torch.FloatTensor(state).to(device)\n",
    "\t\toptions = self.target_net(tensor)\n",
    "\t\ttry:\n",
    "\t\t\treturn np.argmax(options[0].detach().numpy())\n",
    "\t\texcept:\n",
    "\t\t\treturn np.argmax(options[0].detach().cpu().numpy())\n",
    "\n",
    "\tdef optimize(self):\n",
    "\t\tif len(self.memory) < self.batch_size:\n",
    "\t\t\t\treturn\n",
    "\t\ttransitions = self.memory.sample(self.batch_size)\n",
    "\t\t# Transpose the batch (see https://stackoverflow.com/a/19343/3343043 for\n",
    "\t\t# detailed explanation). This converts batch-array of Transitions\n",
    "\t\t# to Transition of batch-arrays.\n",
    "\t\tbatch = Transition(*zip(*transitions))\n",
    "\n",
    "\t\t# Compute a mask of non-final states and concatenate the batch elements\n",
    "\t\t# (a final state would've been the one after which simulation ended)\n",
    "\t\t# print('brw', batch.reward)\n",
    "\t\tnext_state = torch.FloatTensor(batch.next_state).to(device)\n",
    "\t\tnon_final_mask = torch.tensor(tuple(map(lambda s: s is not None, next_state)))\n",
    "\t\tnon_final_next_states = torch.cat([s for s in next_state if s is not None])\n",
    "\t\tstate_batch = torch.FloatTensor(batch.state).to(device)\n",
    "\t\taction_batch = torch.LongTensor(batch.action).to(device)\n",
    "\t\treward_batch = torch.FloatTensor(batch.reward).to(device)\n",
    "\t\t# print('next state', next_state.size())\n",
    "\t\t# print('non_final_mask', non_final_mask.size())\n",
    "\t\t# print('non_final_next_states', non_final_next_states.size())\n",
    "\t\t# print('state_batch', state_batch.size())\n",
    "\t\t# print('action_batch', action_batch.size())\n",
    "\t\t# print('reward_batch', reward_batch.size())\n",
    "\n",
    "\t\t# Compute Q(s_t, a) - the model computes Q(s_t), then we select the\n",
    "\t\t# columns of actions taken. These are the actions which would've been taken\n",
    "\t\t# for each batch state according to policy_net\n",
    "\t\t#state_action_values = self.policy_net(state_batch).reshape((self.batch_size, 3)).gather(1, action_batch.reshape((self.batch_size, 1)))\n",
    "\t\tstate_action_values = self.policy_net(state_batch).reshape((self.batch_size, 3)).gather(1, action_batch.reshape((self.batch_size, 1)))\n",
    "\n",
    "\t\t# Compute V(s_{t+1}) for all next states.\n",
    "\t\t# Expected values of actions for non_final_next_states are computed based\n",
    "\t\t# on the \"older\" target_net; selecting their best reward with max(1)[0].\n",
    "\t\t# This is merged based on the mask, such that we'll have either the expected\n",
    "\t\t# state value or 0 in case the state was final.\n",
    "\t\tnext_state_values = torch.zeros(self.batch_size, device=device)\n",
    "\t\tnext_state_values[non_final_mask] = self.target_net(non_final_next_states).max(1)[0].detach()\n",
    "\t\t# Compute the expected Q values\n",
    "\t\texpected_state_action_values = (next_state_values * self.gamma) + reward_batch\n",
    "\n",
    "\t\t# Compute Huber loss\n",
    "\t\tloss = F.smooth_l1_loss(state_action_values, expected_state_action_values.unsqueeze(1))\n",
    "\n",
    "\t\t# Optimize the model\n",
    "\t\tself.optimizer.zero_grad()\n",
    "\t\tloss.backward()\n",
    "\t\tfor param in self.policy_net.parameters():\n",
    "\t\t\t\tparam.grad.data.clamp_(-1, 1)\n",
    "\t\tself.optimizer.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "# functions\n",
    "def flatten_list(_2d_list):\n",
    "    flat_list = []\n",
    "    # Iterate through the outer list\n",
    "    for element in _2d_list:\n",
    "        if type(element) is list:\n",
    "            # If the element is of type list, iterate through the sublist\n",
    "            for item in element:\n",
    "                flat_list.append(item)\n",
    "        else:\n",
    "            flat_list.append(element)\n",
    "    return flat_list\n",
    "\n",
    "# prints formatted price\n",
    "def formatPrice(n):\n",
    "\treturn (\"-$\" if n < 0 else \"$\") + \"{0:.2f}\".format(abs(n))\n",
    "\n",
    "# returns the vector containing stock data from a fixed file\n",
    "def getStockDataVec(datax):\n",
    "\tvec = []\n",
    "\tfor index, line in datax.iterrows():\n",
    "\t\tif data_size == 3:\n",
    "\t\t\tvec.append(np.array([line['close'], line['ewm'], line['macd_histo']])) #print(line['close'], line['ewm'], line['macd_histo'])else:\n",
    "\t\telse:\n",
    "\t\t\tvec.append(line['close']) #print(line['close'], line['ewm'], line['macd_histo'])\n",
    "  # lines = datax.to_csv().splitlines()\n",
    "\t# for line in lines:\n",
    "\t# \tvec.append([line])\n",
    "\treturn vec\n",
    "\n",
    "\t# for line in lines[1:]:\n",
    "\t# \tclose = line.split(\",\")[4]\n",
    "\t# \tif close != 'null':\n",
    "\t# \t\tvec.append(float(line.split(\",\")[4]))\n",
    "  # \n",
    "\n",
    "# returns the sigmoid\n",
    "def sigmoid(x):\n",
    "\treturn 1 / (1 + np.exp(-x))\n",
    "\n",
    "#100-period sortino ratio\n",
    "def roll_sortino(df): #t: last time ratio\n",
    "  risk_free = 0 #0 percent\n",
    "  returns = (df - df.shift(-1)).to_numpy()[:-1]\n",
    "  return_negative_normal = returns[returns < 0]\n",
    "  return_negative_std = return_negative_normal.std() if len(return_negative_normal) > 0 else 0\n",
    "  sortino_roll = (returns.mean() - risk_free) / return_negative_std * np.sqrt(100) if return_negative_std > 0 else 0\n",
    "  # print(\"srtdf\", return_negative_normal, 'SSSTD', return_negative_std, 'SRLLL', sortino_roll)\n",
    "  # print(\"SRRL\", sortino_roll)\n",
    "  return sortino_roll\n",
    "\n",
    "def sortino(t): #time period: m for minute, h for hour, t: truncated\n",
    "  df_truncated = data_to_modify.head(t)\n",
    "  df_sortino = roll_sortino(df_truncated['dqn_return'].tail(100))\n",
    "  # print(\"srt\", df_truncated['sortino'], df_truncated['dqn_return'])\n",
    "  if t == 0:\n",
    "    data_to_modify.loc[t, 'sortino'] = 0\n",
    "    sortino_ = 0\n",
    "  else:\n",
    "    data_to_modify.loc[t, 'sortino'] = df_sortino\n",
    "    sortino_ = df_sortino\n",
    "  # print(float(sortino_))\n",
    "  return float(sortino_)\n",
    "\n",
    "countx = 0\n",
    "# returns an an n-day state representation ending at time t\n",
    "###################### MAKE THIS [32, 1, 15] INSTEAD OF [32, 15]\n",
    "def getState(data, t, n, cap_now):\n",
    "  global countx\n",
    "  d = t - n + 1\n",
    "  block = data[d:t + 1] if d >= 0 else -d * [data[0]] + data[0:t + 1] # pad with t0\n",
    "  res = []\n",
    "\n",
    "  for i in range(n - 1):\n",
    "    state_ = []\n",
    "    if data_size == 1:\n",
    "      state_ = sigmoid(block[i + 1] - block[i])\n",
    "    else:\n",
    "      state_.append(sigmoid((block[i + 1][0] - block[i][0]))) # price movement\n",
    "      state_.append(sigmoid((block[i + 1][1] - block[i][1]))) # price w.r.t. ema28\n",
    "      state_.append(sigmoid((block[i + 1][0] - cap_now))) # cap now vs price now\n",
    "    res.append(state_)\n",
    "      # print(\"BK\", block)\n",
    "      # print(\"-SIG\", block[i + 1][k] - block[i][k])\n",
    "      # print(\"ST\", state_)\n",
    "  if data_size == 1:\n",
    "    return np.array(res).reshape(1, data_size * window_size)\n",
    "  else:\n",
    "    return np.array(flatten_list(res)).reshape(1, data_size * window_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 0/0\n",
      "--------------------------------\n",
      "Total Return: 0.016521477119305565\n",
      "--------------------------------\n"
     ]
    }
   ],
   "source": [
    "# train\n",
    "agent = Agent(window_size)\n",
    "data = getStockDataVec(data_to_modify)\n",
    "l = len(data) - 1\n",
    "\n",
    "capital = 10000\n",
    "capital_now = capital + 0\n",
    "max_investment = capital + 0\n",
    "mdd = 0\n",
    "closes = []\n",
    "buys = []\n",
    "sells = []\n",
    "\n",
    "results_ = []\n",
    "\n",
    "for e in range(episode_count + 1):\n",
    "\tcapital = 10000\n",
    "\tcapital_now = capital + 0\n",
    "\tmax_investment = capital + 0\n",
    "\tmdd = 0\n",
    "\tcloses = []\n",
    "\tbuys = []\n",
    "\tsells = []\n",
    "\tprint(\"Episode \" + str(e) + \"/\" + str(episode_count))\n",
    "\tstate = getState(data, 0, window_size + 1, capital_now)\n",
    "\tstop = False\n",
    "\n",
    "\tagent.inventory = []\n",
    "\n",
    "\tfor t in range(l):\n",
    "\t\taction = agent.act(state)\n",
    "\t\t# sit\n",
    "\t\treward = 0\n",
    "\n",
    "\t\t# print(agent.inventory, data[t])\n",
    "\t\tif action == 1: # buy\n",
    "\t\t\treward = 0\n",
    "\t\t\tif capital_now and len(agent.inventory) == 0:\n",
    "\t\t\t\tbtc_price = data[t] if data_size == 1 else data[t][0]\n",
    "\t\t\t\tbtc_bought = capital_now/btc_price\n",
    "\t\t\t\tagent.inventory.append((btc_bought, btc_price)) # price\n",
    "\t\t\t\tbuys.append(data[t])\n",
    "\t\t\t\tdata_to_modify.at[t, 'dqn_return'] = capital_now / capital\n",
    "\t\t\t\tdata_to_modify.at[t, 'action'] = 'buy-buy'\n",
    "\t\t\t\tif t == 0:\n",
    "\t\t\t\t\tdata_to_modify.at[t, 'mdd'] = 0\n",
    "\t\t\t\telse:\n",
    "\t\t\t\t\tdata_to_modify.at[t, 'mdd'] = data_to_modify.at[t - 1, 'mdd']\n",
    "\t\t\t\tsortino_current = sortino(t)\n",
    "\t\t\t\tsells.append(None)\n",
    "\t\t\t\t# calculate sortino\n",
    "\t\t\t\tcapital_now = 0\n",
    "\t\t\telse:\n",
    "\t\t\t\tif (len(agent.inventory) > 0):\n",
    "\t\t\t\t\tcapital_now = agent.inventory[0][0] * data[t] if data_size == 1 else agent.inventory[0][0] * data[t][0]\n",
    "\t\t\t\t\tdata_to_modify.at[t, 'action'] = 'buy-hold-full'\n",
    "\t\t\t\t\tdata_to_modify.at[t, 'dqn_return'] = capital_now / capital\n",
    "\t\t\t\t\tif capital_now > max_investment:\n",
    "\t\t\t\t\t\tmax_investment = capital_now\n",
    "\t\t\t\t\tif (max_investment - capital_now) / max_investment > mdd:\n",
    "\t\t\t\t\t\tmdd = (max_investment - capital_now) / max_investment\n",
    "\t\t\t\telse:\n",
    "\t\t\t\t\tdata_to_modify.at[t, 'dqn_return'] = capital_now / capital\n",
    "\t\t\t\t\tdata_to_modify.at[t, 'action'] = 'buy-hold-nocapital'\n",
    "\t\t\t\tdata_to_modify.at[t, 'mdd'] = data_to_modify.at[t - 1, 'mdd']\n",
    "\t\t\t\tsortino_current = sortino(t)\n",
    "\t\t\t\tbuys.append(None)\n",
    "\t\t\t\tsells.append(None)\n",
    "\t\t\t#if capital > data[t]:\n",
    "\t\t\t\t#agent.inventory.append(data[t])\n",
    "\t\t\t\t#buys.append(data[t])\n",
    "\t\t\t\t#sells.append(None)\n",
    "\t\t\t\t#capital -= data[t]\n",
    "\t\t\t#else:\n",
    "\t\t\t\t#buys.append(None)\n",
    "\t\t\t\t#sells.append(None)\n",
    "        \n",
    "\t\telif action == 2: # sell\n",
    "\t\t\tif len(agent.inventory) > 0:\n",
    "\t\t\t\tbtc_bought, bought_price = agent.inventory.pop(0)\n",
    "\t\t\t\tcapital_now = btc_bought * data[t] if data_size == 1 else btc_bought * data[t][0]\n",
    "\t\t\t\tdata_to_modify.at[t, 'dqn_return'] = capital_now / capital\n",
    "\t\t\t\tdata_to_modify.at[t, 'action'] = 'sell-sell'\n",
    "\t\t\t\treward_1 = 100 * (capital_now - btc_bought * bought_price) / (btc_bought * bought_price) # reward 1: Return in %\n",
    "\t\t\t\t# print(\"BB\", int(btc_bought * 10000), \"BP\", int(bought_price), \"FROM\", int(btc_bought * bought_price), \"TO\", int(capital_now), \"RET\", int(10*reward_1)/10, \"AINV\", agent.inventory)\n",
    "\t\t\t\tif capital_now > max_investment:\n",
    "\t\t\t\t\tmax_investment = capital_now\n",
    "\t\t\t\tif (max_investment - capital_now) / max_investment > mdd:\n",
    "\t\t\t\t\tmdd = (max_investment - capital_now) / max_investment\n",
    "\t\t\t\tsortino_current = sortino(t)\n",
    "\t\t\t\tdata_to_modify.at[t, 'mdd'] = mdd\n",
    "\t\t\t\t# calculate mdd??? sortino???\n",
    "        # if mdd decreases = penalty, else reward\n",
    "        # if sortino decreases = penalty, else reward\n",
    "\t\t\t\treward_2 = data_to_modify.at[t - 1, 'mdd'] - mdd #mdd\n",
    "\t\t\t\treward_3 = sortino_current / np.sqrt(100) #sortino\n",
    "\t\t\t\treward = max(reward_1 + reward_2 + reward_3, 0) #reward = max(data[t] - bought_price, 0)\n",
    "\t\t\t\tdata_to_modify.at[t, 'reward'] = \"[{0:.2f}]{1:.2f}/{2:.2f}/{3:.2f}\".format(reward, reward_1, reward_2, reward_3)\n",
    "\t\t\t\t# print(reward_1, reward_2, reward_3)\n",
    "\t\t\t\tbuys.append(None)\n",
    "\t\t\t\tsells.append(data[t])\n",
    "\t\t\telse:\n",
    "\t\t\t\treward = 0\n",
    "\t\t\t\tdata_to_modify.at[t, 'dqn_return'] = capital_now / capital\n",
    "\t\t\t\tdata_to_modify.at[t, 'action'] = 'sell-noasset'\n",
    "\t\t\t\tif t == 0:\n",
    "\t\t\t\t\tdata_to_modify.at[t, 'mdd'] = 0\n",
    "\t\t\t\telse:\n",
    "\t\t\t\t\tdata_to_modify.at[t, 'mdd'] = data_to_modify.at[t - 1, 'mdd']\n",
    "\t\t\t\tsortino_current = sortino(t)\n",
    "\t\t\t\tbuys.append(None)\n",
    "\t\t\t\tsells.append(None)\n",
    "        \n",
    "\t\telif action == 0: # hodl\n",
    "\t\t\treward = 0\n",
    "\t\t\tif capital_now > 0: # hodl idle\n",
    "\t\t\t\tdata_to_modify.at[t, 'dqn_return'] = capital_now / capital\n",
    "\t\t\t\tdata_to_modify.at[t, 'action'] = 'idle'\n",
    "\t\t\telse: # hodl hodl\n",
    "\t\t\t\ttry:\n",
    "\t\t\t\t\tdata_to_modify.at[t, 'dqn_return'] = (agent.inventory[0][0] * data[t]) / capital if data_size == 1 else (agent.inventory[0][0] * data[t][0]) / capital\n",
    "\t\t\t\texcept:\n",
    "\t\t\t\t\tif t > 0:\n",
    "\t\t\t\t\t\tdata_to_modify.at[t, 'dqn_return'] = data_to_modify.at[t - 1, 'dqn_return']\n",
    "\t\t\t\t\telse:\n",
    "\t\t\t\t\t\tdata_to_modify.at[t, 'dqn_return'] = 1\n",
    "\t\t\t\tdata_to_modify.at[t, 'action'] = 'hodl'\n",
    "\t\t\tif t == 0:\n",
    "\t\t\t\tdata_to_modify.at[t, 'mdd'] = 0\n",
    "\t\t\telse:\n",
    "\t\t\t\tdata_to_modify.at[t, 'mdd'] = data_to_modify.at[t - 1, 'mdd']\n",
    "\t\t\tsortino_current = sortino(t)\n",
    "\t\t\tbuys.append(None)\n",
    "\t\t\tsells.append(None)\n",
    "\n",
    "\t\tif reward == 0:\n",
    "\t\t\tdata_to_modify.at[t, 'reward'] = \"0\"\n",
    "\t\tdone = True if t == l - 1 else False\n",
    "\t\t# print(int(reward * 10), end=' ')\n",
    "\t\tif data_size == 1:\n",
    "\t\t\tcapital_next = agent.inventory[0][0] * data[t] if len(agent.inventory) else capital_now\n",
    "\t\telse:\n",
    "\t\t\tcapital_next = agent.inventory[0][0] * data[t][0] if len(agent.inventory) else capital_now\n",
    "\t\tnext_state = getState(data, t + 1, window_size + 1, capital_next)\n",
    "\t\tagent.memory.push(state, action, next_state, reward)\n",
    "\t\tstate = next_state\n",
    "\n",
    "\t\tif done:\n",
    "\t\t\tprint(\"--------------------------------\")\n",
    "\t\t\tif data_size == 1:\n",
    "\t\t\t\tcapital_final = agent.inventory[0][0] * data[t] if len(agent.inventory) else capital_now\n",
    "\t\t\telse:\n",
    "\t\t\t\tcapital_final = agent.inventory[0][0] * data[t][0] if len(agent.inventory) else capital_now\n",
    "\t\t\tresults_.append(capital_final / capital)\n",
    "\t\t\tprint(\"Total Return: \" + str((capital_final - capital) / capital))\n",
    "\t\t\tprint(\"--------------------------------\")\n",
    "\t\t\t# x = input()\n",
    "\t\t\t# if x == 'y':\n",
    "\t\t\t# \tstop = True\n",
    "\t\tagent.optimize()\n",
    "\tif stop:\n",
    "\t\tbreak\n",
    "\n",
    "\tif e % 10 == 0:\n",
    "\t\tagent.target_net.load_state_dict(agent.policy_net.state_dict())\n",
    "\t\ttorch.save(agent.policy_net, \"models/B2/policy_model\" + model_file_suffix)\n",
    "\t\ttorch.save(agent.target_net, \"models/B2/target_model\" + model_file_suffix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0165214771193056\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "def moving_average(a, n=3) :\n",
    "    pad = np.array([capital for i in range(n - 1)])\n",
    "    ret = np.cumsum(a, dtype=float)\n",
    "    ret[n:] = ret[n:] - ret[:-n]\n",
    "    return ret[n - 1:] / n\n",
    "\n",
    "xpoints = np.array([s for s in range(len(results_))])\n",
    "ypoints = np.array([s for s in results_])\n",
    "ypoints_ma = moving_average(ypoints, 15)\n",
    "\n",
    "plt.plot(xpoints, ypoints)\n",
    "plt.plot(xpoints[14:], ypoints_ma)\n",
    "plt.show()\n",
    "\n",
    "print(ypoints.mean())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>time</th>\n",
       "      <th>high</th>\n",
       "      <th>low</th>\n",
       "      <th>open</th>\n",
       "      <th>close</th>\n",
       "      <th>ewm</th>\n",
       "      <th>macd_histo</th>\n",
       "      <th>return</th>\n",
       "      <th>dqn_return</th>\n",
       "      <th>action</th>\n",
       "      <th>mdd</th>\n",
       "      <th>sortino</th>\n",
       "      <th>reward</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2023-02-14 04:40:00</td>\n",
       "      <td>21744.54</td>\n",
       "      <td>21740.71</td>\n",
       "      <td>21744.42</td>\n",
       "      <td>21740.88</td>\n",
       "      <td>21740.880000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>sell-noasset</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2023-02-14 04:41:00</td>\n",
       "      <td>21744.88</td>\n",
       "      <td>21740.58</td>\n",
       "      <td>21740.88</td>\n",
       "      <td>21744.09</td>\n",
       "      <td>21741.101379</td>\n",
       "      <td>0.204855</td>\n",
       "      <td>0.000148</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>sell-noasset</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2023-02-14 04:42:00</td>\n",
       "      <td>21744.64</td>\n",
       "      <td>21743.74</td>\n",
       "      <td>21744.09</td>\n",
       "      <td>21744.55</td>\n",
       "      <td>21741.339215</td>\n",
       "      <td>0.351404</td>\n",
       "      <td>0.000021</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>buy-buy</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2023-02-14 04:43:00</td>\n",
       "      <td>21744.55</td>\n",
       "      <td>21740.33</td>\n",
       "      <td>21744.55</td>\n",
       "      <td>21740.52</td>\n",
       "      <td>21741.282718</td>\n",
       "      <td>0.166384</td>\n",
       "      <td>-0.000185</td>\n",
       "      <td>0.999815</td>\n",
       "      <td>hodl</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2023-02-14 04:44:00</td>\n",
       "      <td>21740.52</td>\n",
       "      <td>21733.91</td>\n",
       "      <td>21740.52</td>\n",
       "      <td>21734.18</td>\n",
       "      <td>21740.792875</td>\n",
       "      <td>-0.364556</td>\n",
       "      <td>-0.000292</td>\n",
       "      <td>0.999523</td>\n",
       "      <td>sell-sell</td>\n",
       "      <td>0.000477</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>[-0.05]-0.05/-0.00/0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1996</th>\n",
       "      <td>2023-02-15 13:56:00</td>\n",
       "      <td>22734.46</td>\n",
       "      <td>22722.95</td>\n",
       "      <td>22732.99</td>\n",
       "      <td>22723.87</td>\n",
       "      <td>22734.866055</td>\n",
       "      <td>-0.406212</td>\n",
       "      <td>-0.000401</td>\n",
       "      <td>1.017548</td>\n",
       "      <td>buy-buy</td>\n",
       "      <td>0.015976</td>\n",
       "      <td>0.165158</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1997</th>\n",
       "      <td>2023-02-15 13:57:00</td>\n",
       "      <td>22723.87</td>\n",
       "      <td>22712.32</td>\n",
       "      <td>22723.87</td>\n",
       "      <td>22712.90</td>\n",
       "      <td>22733.351155</td>\n",
       "      <td>-2.116000</td>\n",
       "      <td>-0.000483</td>\n",
       "      <td>1.017057</td>\n",
       "      <td>buy-hold-full</td>\n",
       "      <td>0.015976</td>\n",
       "      <td>0.150024</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1998</th>\n",
       "      <td>2023-02-15 13:58:00</td>\n",
       "      <td>22713.26</td>\n",
       "      <td>22703.47</td>\n",
       "      <td>22712.90</td>\n",
       "      <td>22704.37</td>\n",
       "      <td>22731.352455</td>\n",
       "      <td>-3.648014</td>\n",
       "      <td>-0.000376</td>\n",
       "      <td>1.016675</td>\n",
       "      <td>buy-hold-full</td>\n",
       "      <td>0.015976</td>\n",
       "      <td>0.179371</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1999</th>\n",
       "      <td>2023-02-15 13:59:00</td>\n",
       "      <td>22704.37</td>\n",
       "      <td>22698.08</td>\n",
       "      <td>22704.37</td>\n",
       "      <td>22700.95</td>\n",
       "      <td>22729.255734</td>\n",
       "      <td>-4.653869</td>\n",
       "      <td>-0.000151</td>\n",
       "      <td>1.016521</td>\n",
       "      <td>buy-hold-full</td>\n",
       "      <td>0.015976</td>\n",
       "      <td>0.207814</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2000</th>\n",
       "      <td>2023-02-15 14:00:00</td>\n",
       "      <td>22702.74</td>\n",
       "      <td>22697.34</td>\n",
       "      <td>22700.95</td>\n",
       "      <td>22699.29</td>\n",
       "      <td>22727.189131</td>\n",
       "      <td>-5.154282</td>\n",
       "      <td>-0.000073</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2001 rows × 13 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                    time      high       low      open     close  \\\n",
       "0    2023-02-14 04:40:00  21744.54  21740.71  21744.42  21740.88   \n",
       "1    2023-02-14 04:41:00  21744.88  21740.58  21740.88  21744.09   \n",
       "2    2023-02-14 04:42:00  21744.64  21743.74  21744.09  21744.55   \n",
       "3    2023-02-14 04:43:00  21744.55  21740.33  21744.55  21740.52   \n",
       "4    2023-02-14 04:44:00  21740.52  21733.91  21740.52  21734.18   \n",
       "...                  ...       ...       ...       ...       ...   \n",
       "1996 2023-02-15 13:56:00  22734.46  22722.95  22732.99  22723.87   \n",
       "1997 2023-02-15 13:57:00  22723.87  22712.32  22723.87  22712.90   \n",
       "1998 2023-02-15 13:58:00  22713.26  22703.47  22712.90  22704.37   \n",
       "1999 2023-02-15 13:59:00  22704.37  22698.08  22704.37  22700.95   \n",
       "2000 2023-02-15 14:00:00  22702.74  22697.34  22700.95  22699.29   \n",
       "\n",
       "               ewm  macd_histo    return  dqn_return         action       mdd  \\\n",
       "0     21740.880000    0.000000       NaN    1.000000   sell-noasset  0.000000   \n",
       "1     21741.101379    0.204855  0.000148    1.000000   sell-noasset  0.000000   \n",
       "2     21741.339215    0.351404  0.000021    1.000000        buy-buy  0.000000   \n",
       "3     21741.282718    0.166384 -0.000185    0.999815           hodl  0.000000   \n",
       "4     21740.792875   -0.364556 -0.000292    0.999523      sell-sell  0.000477   \n",
       "...            ...         ...       ...         ...            ...       ...   \n",
       "1996  22734.866055   -0.406212 -0.000401    1.017548        buy-buy  0.015976   \n",
       "1997  22733.351155   -2.116000 -0.000483    1.017057  buy-hold-full  0.015976   \n",
       "1998  22731.352455   -3.648014 -0.000376    1.016675  buy-hold-full  0.015976   \n",
       "1999  22729.255734   -4.653869 -0.000151    1.016521  buy-hold-full  0.015976   \n",
       "2000  22727.189131   -5.154282 -0.000073         NaN            NaN       NaN   \n",
       "\n",
       "       sortino                   reward  \n",
       "0     0.000000                        0  \n",
       "1     0.000000                        0  \n",
       "2     0.000000                        0  \n",
       "3     0.000000                        0  \n",
       "4     0.000000  [-0.05]-0.05/-0.00/0.00  \n",
       "...        ...                      ...  \n",
       "1996  0.165158                        0  \n",
       "1997  0.150024                        0  \n",
       "1998  0.179371                        0  \n",
       "1999  0.207814                        0  \n",
       "2000       NaN                      NaN  \n",
       "\n",
       "[2001 rows x 13 columns]"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pickle\n",
    "pickle.dump({'name': 'minute_model_bear', 'ypoints' :ypoints, 'yma': ypoints_ma, 'traddata': data_to_modify}, open(\"models/B2/minutebear_3.pkl\", 'ab'))\n",
    "data_to_modify"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "f3ce3df792d36067c304b10e101c0644826d26e159008826d766ba61b27006a4"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
